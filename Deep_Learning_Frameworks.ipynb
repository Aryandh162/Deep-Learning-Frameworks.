{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Assignment Question"
      ],
      "metadata": {
        "id": "nP_hw6AHKGkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x"
      ],
      "metadata": {
        "id": "H-o6Tc7zKQ9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=>  \n",
        "##TensorFlow 2.0 vs TensorFlow 1.x\n",
        "* API Cleanup: TensorFlow 2.0 removes redundant and duplicate APIs that existed in 1.x, leading to a more streamlined and consistent library.\n",
        "* API Consistency: TensorFlow 2.0 makes APIs more consistent. Examples provided include unified RNNs and unified Optimizers, suggesting a more standardized way of building and training models.\n",
        "* Functions over Sessions: TensorFlow 2.0 prefers using Python functions over the session-based execution model that was prominent in 1.x. This makes the code feel more like standard Python.\n",
        "* Eager Execution by Default: In TensorFlow 2.0, Eager execution is enabled by default. Eager execution allows you to evaluate operations immediately, making debugging and development easier compared to the graph-based execution in TensorFlow 1.x where you had to build a graph and then run it in a session. TensorFlow 2.0 integrates better with the Python runtime due to this."
      ],
      "metadata": {
        "id": "vFl25ZBKMTRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How do you install TensorFlow 2.0"
      ],
      "metadata": {
        "id": "hcIvpqz2KoFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> The primary way to install TensorFlow 2.0 is by using Python's package manager, pip.\n",
        "\n",
        "Here are the general steps:\n",
        "\n",
        "Check System Requirements: Ensure your system meets the requirements. For example, Ubuntu 16.04 or higher (64-bit) is a requirement for the official packages [2]. You'll also need a supported Python version and pip version greater than 19.0\n",
        "\n",
        "Create a Virtual Environment (Recommended): It's highly recommended to create a virtual environment to isolate your project dependencies. This helps avoid conflicts with other Python projects on your system."
      ],
      "metadata": {
        "id": "79E1klKrMkLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the primary function of the tf.function in TensorFlow 2.0"
      ],
      "metadata": {
        "id": "EyzvzoptKp6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> he primary function of tf.function in TensorFlow 2.0 is to convert regular Python functions that use TensorFlow operations into a callable TensorFlow Graph."
      ],
      "metadata": {
        "id": "z2MUd6WWMtuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the purpose of the Model class in TensorFlow 2.0"
      ],
      "metadata": {
        "id": "RcQSkDKYKro9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> the primary purpose of the Model class in TensorFlow 2.0 (specifically within the Keras API, which is the recommended high-level API in TensorFlow 2.0) is to group layers and represent a model's architecture and training capabilities."
      ],
      "metadata": {
        "id": "EuHeJ2kMP-Vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do you create a neural network using TensorFlow 2.0"
      ],
      "metadata": {
        "id": "KNE2iSsgKtVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> the primary purpose of the Model class in TensorFlow 2.0 (specifically within the Keras API, which is the recommended high-level API in TensorFlow 2.0) is to group layers and represent a model's architecture and training capabilities."
      ],
      "metadata": {
        "id": "UckwQvFOQA1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the importance of Tensor Space in TensorFlow"
      ],
      "metadata": {
        "id": "5bY3grNSKuyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=>  Tensors are multi-dimensional arrays. Their shape explicitly defines the organization of the data within the tensor – how many dimensions it has (its rank) and how many elements are along each axis (or dimension). Without understanding the shape, you wouldn't know how your data is structured or how to access specific elements.\n",
        "\n"
      ],
      "metadata": {
        "id": "CJS17vwMQJCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How can TensorBoard be integrated with TensorFlow 2.0"
      ],
      "metadata": {
        "id": "Wt2FI0j5KwOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> TensorFlow code in Python while still benefiting from the performance and deployment advantages of TensorFlow's graph execution. It's a key feature in TensorFlow 2.0 that promotes a balance between imperative programming and optimized graph-based execution."
      ],
      "metadata": {
        "id": "AHrG4y3FQQSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the purpose of TensorFlow Playground"
      ],
      "metadata": {
        "id": "9l-ZcDvKKx6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=>  TensorFlow Playground provides a hands-on environment where you can experiment with different neural network architectures, hyperparameters, and datasets without writing any code. This interactive approach makes it easier to grasp how neural networks learn and make predictions."
      ],
      "metadata": {
        "id": "14GbZBBaQW22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is Netron, and how is it useful for deep learning models"
      ],
      "metadata": {
        "id": "P4oggnHsKz30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> The tool visually represents the neural network's structure, including its layers, neurons, and connections. As the network trains, you can observe how the weights and biases change and how the decision boundary evolves."
      ],
      "metadata": {
        "id": "vDfSyfbdQaKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the difference between TensorFlow and PyTorch"
      ],
      "metadata": {
        "id": "F5gCdwg5K1b8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> TensorFlow deep learning library is developed by the Google Brain engineering team. It was open source licensed on the 2015 and has since then become very popular for its flexibility and also scalability. In essence, it is employed to roll out of the deep learning architectures.\n",
        "\n",
        " which has gained recognition for putting the things straightforward and also flexible. It was basically launched as an Open-Source Library for the purpose of training the deep learning algorithms in 2016. It is often applauded for its simplicity and also flexibility, which serves as a very powerful tool for the engineers whenever they want to do Debug and also experiment with some of the algorithms."
      ],
      "metadata": {
        "id": "1ulUvPMeQpLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. How do you install PyTorch"
      ],
      "metadata": {
        "id": "3yR--zD-K3Oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> which has gained recognition for putting the things straightforward and also flexible. It was basically launched as an Open-Source Library for the purpose of training the deep learning algorithms in 2016. It is often applauded for its simplicity and also flexibility, which serves as a very powerful tool for the engineers whenever they want to do Debug and also experiment with some of the algorithms."
      ],
      "metadata": {
        "id": "KsrvUvybhipZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the basic structure of a PyTorch neural network"
      ],
      "metadata": {
        "id": "TifvBmKYK48A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> PyTorch neural network typically involves subclassing the torch.nn.Module class and defining the network's layers and forward pass."
      ],
      "metadata": {
        "id": "-2iHeuceihG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is the significance of tensors in PyTorch\n"
      ],
      "metadata": {
        "id": "qY9CrRgPK6j-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> the fundamental data structure in PyTorch. Their significance lies in being the central building blocks for all computations and operations within the framework."
      ],
      "metadata": {
        "id": "OiGEEKPoinuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch\n"
      ],
      "metadata": {
        "id": "Vp5ocFyXK8cM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> PyTorch's automatic differentiation engine, Autograd, works directly with tensors. Tensors in PyTorch can track the operations performed on them and automatically compute gradients [1]. This is fundamental for backpropagation, the algorithm used to train neural networks by adjusting model parameters based on the gradients of the loss function. The ability of tensors to participate in gradient computation is a key differentiator from standard NumPy arrays."
      ],
      "metadata": {
        "id": "cjKdL70Vis0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is the purpose of the torch.optim module in PyTorch"
      ],
      "metadata": {
        "id": "KJ3YElXbK-YO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> A major advantage of tensors in PyTorch is their ability to be moved to and computed on GPUs. This is crucial for accelerating the computationally intensive operations involved in training deep neural networks . Without tensors that can leverage GPU power, deep learning training would be significantly slower."
      ],
      "metadata": {
        "id": "7aR7ca-yiyLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What are some common activation functions used in neural networks"
      ],
      "metadata": {
        "id": "O5KxopSjLABY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> PyTorch's tensors are tightly integrated with its eager execution and dynamic graph capabilities. You can define and manipulate tensors interactively, and the computation graph is built dynamically as you perform operations on them ."
      ],
      "metadata": {
        "id": "MSpYtHBbi8L2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch"
      ],
      "metadata": {
        "id": "7mIKXue5LBpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> While the former defines nn.Module classes, the latter uses a functional (stateless) approach.\n",
        "To dig a bit deeper: nn.Modules are defined as Python classes and have attributes, e.g. a nn.Conv2d module will have some internal attributes like self.weight. F.conv2d however just defines the operation and needs all arguments to be passed (including the weights and bias). Internally the modules will usually call their functional counterpart in the forward method somewhere."
      ],
      "metadata": {
        "id": "RYqfuwFIjuJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. How can you monitor training progress in TensorFlow 2.0"
      ],
      "metadata": {
        "id": "clgmuJLVLDlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> PyTorch tensors can be easily converted to and from NumPy arrays, making it convenient to work with existing NumPy-based code and data"
      ],
      "metadata": {
        "id": "SmL-y5eSjy4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How does the Keras API fit into TensorFlow 2.0"
      ],
      "metadata": {
        "id": "_AUeJZZzLFJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow 2.0 officially adopted Keras as its primary high-level API. This means that when you install TensorFlow 2.0, Keras is automatically included and is the standard way to define and train models."
      ],
      "metadata": {
        "id": "C7goGqE_j7Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0"
      ],
      "metadata": {
        "id": "BUi95fD_LG_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=>  Keras provides user-friendly building blocks like Layers and Models [1]. This simplifies the process of creating complex neural network architectures by allowing you to stack or connect pre-defined layers. You don't need to deal with low-level TensorFlow operations as much when using Keras."
      ],
      "metadata": {
        "id": "c7cKYcnekBlq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch?"
      ],
      "metadata": {
        "id": "YDDInp7vLIlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Training a deep neural network from scratch requires a significant amount of time and computational resources (GPUs). Pre-trained models have already learned powerful features from vast datasets (like ImageNet for image tasks). By using a pre-trained model, you can leverage these learned features and significantly reduce the time required to train your model on a new, smaller dataset."
      ],
      "metadata": {
        "id": "PAz-MixVkJUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Practical Questions"
      ],
      "metadata": {
        "id": "RHuzMs4XLRuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. How do you install and verify that TensorFlow 2.0 was installed successfully"
      ],
      "metadata": {
        "id": "b_PKt6NALVfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for the above Ques.\n",
        "!pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "hello = tf.constant('Hello, TensorFlow!')\n",
        "print(hello.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IEg6egEL12x",
        "outputId": "f43bbe75-ef56-4002-80cc-bed4f68936b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n",
            "b'Hello, TensorFlow!'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How can you define a simple function in TensorFlow 2.0 to perform addition"
      ],
      "metadata": {
        "id": "hCbf7Qp5Lk_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for the above Ques.\n",
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def add_numbers(a, b):\n",
        "\n",
        "  return a + b\n",
        "\n",
        "tensor_a = tf.constant([1, 2, 3])\n",
        "tensor_b = tf.constant([4, 5, 6])\n",
        "\n",
        "result_tensor = add_numbers(tensor_a, tensor_b)\n",
        "\n",
        "print(\"Tensor A:\", tensor_a)\n",
        "print(\"Tensor B:\", tensor_b)\n",
        "print(\"Result of addition (tf.function):\", result_tensor)\n",
        "\n",
        "tensor_c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
        "tensor_d = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
        "\n",
        "result_float_tensor = add_numbers(tensor_c, tensor_d)\n",
        "\n",
        "print(\"\\nTensor C:\", tensor_c)\n",
        "print(\"Tensor D:\", tensor_d)\n",
        "print(\"Result of addition (tf.function with floats):\", result_float_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn3K1PMQL86g",
        "outputId": "4dc23146-9564-4d83-f343-8644b0b38d91"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A: tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
            "Tensor B: tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
            "Result of addition (tf.function): tf.Tensor([5 7 9], shape=(3,), dtype=int32)\n",
            "\n",
            "Tensor C: tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]], shape=(2, 2), dtype=float32)\n",
            "Tensor D: tf.Tensor(\n",
            "[[5. 6.]\n",
            " [7. 8.]], shape=(2, 2), dtype=float32)\n",
            "Result of addition (tf.function with floats): tf.Tensor(\n",
            "[[ 6.  8.]\n",
            " [10. 12.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. How can you create a simple neural network in TensorFlow 2.0 with one hidden layer"
      ],
      "metadata": {
        "id": "NZXYXVuULm3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for the above Ques.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "model = Sequential([\n",
        "\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "F7EUvl6DL9cF",
        "outputId": "9973543d-41d7-4c1e-ae77-fcfa77fbe4eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How can you visualize the training progress using TensorFlow and Matplotlib"
      ],
      "metadata": {
        "id": "f_zoBzC_Lo2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for the above Ques.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "num_samples = 1000\n",
        "input_features = 20\n",
        "num_classes = 2\n",
        "\n",
        "x_train = np.random.rand(num_samples, input_features).astype(np.float32)\n",
        "y_train = np.random.randint(0, num_classes, num_samples)\n",
        "\n",
        "\n",
        "x_val = np.random.rand(int(num_samples * 0.2), input_features).astype(np.float32)\n",
        "y_val = np.random.randint(0, num_classes, int(num_samples * 0.2))\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(input_features,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax') # Output layer for classification\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), verbose=0)\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hunwIqlHL99e",
        "outputId": "cd48c42e-a664-4910-86c4-11235d449212"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do you install PyTorch and verify the PyTorch installation"
      ],
      "metadata": {
        "id": "Gjm4MI5PLqpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for the above Ques.\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.get_device_properties(0))\n",
        "print(torch.cuda.get_device_capability(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "id": "4lhccgzRL-XE",
        "outputId": "6f347808-2814-45a1-b261-3df8cac519c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "tensor([[0.0958, 0.3345, 0.5593],\n",
            "        [0.9000, 0.3881, 0.8339],\n",
            "        [0.4458, 0.4412, 0.5447],\n",
            "        [0.9843, 0.9871, 0.4115],\n",
            "        [0.2644, 0.4433, 0.9991]])\n",
            "False\n",
            "12.4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-724456819.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_capability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \"\"\"\n\u001b[0;32m--> 523\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How do you create a simple neural network in PyTorch"
      ],
      "metadata": {
        "id": "SmMlziEnLsek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for the above Ques.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        out = self.fc2(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "input_dim = 10\n",
        "hidden_dim = 20\n",
        "output_dim = 1\n",
        "\n",
        "model = SimpleNN(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "print(model)\n",
        "\n",
        "dummy_input = torch.randn(1, input_dim)\n",
        "\n",
        "output = model(dummy_input)\n",
        "print(\"\\nDummy input shape:\", dummy_input.shape)\n",
        "print(\"Output shape:\", output.shape)\n",
        "\n",
        "\n",
        "dummy_data = torch.randn(100, input_dim)\n",
        "dummy_labels = torch.randn(100, output_dim)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hufJOL0tL-rw",
        "outputId": "8e49f38c-b52e-42bf-cc29-982a37b165a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
            "  (fc2): Linear(in_features=20, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Dummy input shape: torch.Size([1, 10])\n",
            "Output shape: torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How do you define a loss function and optimizer in PyTorch"
      ],
      "metadata": {
        "id": "uAqV-97-Lv7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for the above Ques.\n",
        "import torch\n",
        "import torch.nn as nn # For loss functions\n",
        "import torch.optim as optim # For optimizers\n",
        "\n",
        "\n",
        "criterion_mse = nn.MSELoss()\n",
        "print(\"Defined MSE Loss Function:\", criterion_mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INoBl_fQL_E_",
        "outputId": "20f5c3d9-c579-4d8b-f6a5-ab864c95424a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined MSE Loss Function: MSELoss()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. How do you implement a custom loss function in PyTorch\n"
      ],
      "metadata": {
        "id": "fshlZdppLxdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for the above Ques.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def custom_mean_absolute_error(outputs, targets):\n",
        "\n",
        "  if outputs.shape != targets.shape:\n",
        "      raise ValueError(\"Outputs and targets must have the same shape\")\n",
        "\n",
        "  abs_diff = torch.abs(outputs - targets)\n",
        "\n",
        "  mae_loss = torch.mean(abs_diff)\n",
        "\n",
        "  return mae_loss\n",
        "\n",
        "outputs = torch.randn(5, 1, requires_grad=True)\n",
        "targets = torch.randn(5, 1)\n",
        "\n",
        "loss = custom_mean_absolute_error(outputs, targets)\n",
        "\n",
        "print(\"Outputs:\", outputs)\n",
        "print(\"Targets:\", targets)\n",
        "print(\"Custom MAE Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTUsv9pZL_bv",
        "outputId": "e5157e4c-ef5b-4f07-efa8-f834ecde85e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs: tensor([[-1.1486],\n",
            "        [-1.4683],\n",
            "        [-0.2754],\n",
            "        [-0.2843],\n",
            "        [ 1.5282]], requires_grad=True)\n",
            "Targets: tensor([[ 0.4344],\n",
            "        [-0.0587],\n",
            "        [-0.0947],\n",
            "        [-0.0288],\n",
            "        [ 0.4725]])\n",
            "Custom MAE Loss: tensor(0.8969, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. How do you save and load a TensorFlow model"
      ],
      "metadata": {
        "id": "K5Vm1qxULzO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for the above Ques.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "import os # Import os module to create directories\n",
        "\n",
        "model_save_dir = 'saved_model_example'\n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Define a simple model (as in previous examples)\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "saved_model_path = os.path.join(model_save_dir, 'my_saved_model.keras')\n",
        "\n",
        "model.save(saved_model_path)\n",
        "print(f\"Model saved to: {saved_model_path}\")\n",
        "\n",
        "loaded_model = tf.keras.models.load_model(saved_model_path)\n",
        "print(\"\\nModel loaded successfully!\")\n",
        "\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "ozWshxORL_24",
        "outputId": "22c5aac3-855a-4bdf-ae99-b753823a1a3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: saved_model_example/my_saved_model.keras\n",
            "\n",
            "Model loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 10 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m305,312\u001b[0m (1.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">305,312</span> (1.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m203,542\u001b[0m (795.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,542</span> (795.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3331db8f"
      },
      "source": [
        "You can install TensorFlow 2.0 using pip. It's generally recommended to use a virtual environment to avoid conflicts with other Python packages.\n",
        "\n",
        "Here are the steps:"
      ]
    }
  ]
}